# Training

For all language pairs we used the same model configuration (transformers-base). The training and validation logs for both versions (hplt, tatoeba and opus_tatoeba) are provided in the respective language pair directories.
